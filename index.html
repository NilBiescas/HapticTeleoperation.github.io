<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Haptic Teleoperation and Learning from Demonstration with the Franka Robotic Arm</title>
  <meta name="description" content="Final presentation: teleoperation of a Franka Panda with a Falcon haptic device, plus Learning from Demonstration using GMM/GMR and TP-GMM." />

  <style>
    :root{
      --bg: #0b0f17;
      --panel: #111a2b;
      --panel-2: #0f1626;
      --text: #e8eefc;
      --muted: #b7c3df;
      --line: rgba(232, 238, 252, 0.14);
      --accent: #7aa2ff;
      --accent-2: #8df0d6;
      --shadow: 0 10px 30px rgba(0,0,0,0.35);
      --radius: 18px;
      --maxw: 1100px;
    }
    * { box-sizing: border-box; }
    html { scroll-behavior: smooth; }
    body{
      margin: 0;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      background:
        radial-gradient(1200px 700px at 15% 10%, rgba(122,162,255,0.25), transparent 60%),
        radial-gradient(900px 600px at 80% 20%, rgba(141,240,214,0.12), transparent 55%),
        var(--bg);
      color: var(--text);
      line-height: 1.55;
    }
    a{ color: var(--text); text-decoration: none; }
    a:hover{ text-decoration: underline; }
    .wrap{ max-width: var(--maxw); margin: 0 auto; padding: 28px 20px 64px; }

    .nav{
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 18px;
      padding: 14px 16px;
      border: 1px solid var(--line);
      background: rgba(17,26,43,0.65);
      backdrop-filter: blur(10px);
      border-radius: 999px;
      box-shadow: var(--shadow);
      position: sticky;
      top: 14px;
      z-index: 10;
    }
    .brand{
      display: flex;
      align-items: center;
      gap: 10px;
      white-space: nowrap;
    }
    .dot{
      width: 10px;
      height: 10px;
      border-radius: 999px;
      background: linear-gradient(135deg, var(--accent), var(--accent-2));
      box-shadow: 0 0 0 5px rgba(122,162,255,0.12);
    }
    .brand strong{ font-size: 14px; letter-spacing: 0.4px; }
    .navlinks{
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      justify-content: flex-end;
    }
    .pill{
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border: 1px solid var(--line);
      border-radius: 999px;
      background: rgba(15,22,38,0.5);
      font-size: 13px;
      color: var(--muted);
    }
    .pill:hover{ color: var(--text); border-color: rgba(232,238,252,0.25); }
    /* Rainbow attention pill (Videos) */
    .pill--rainbow{
      border: 1px solid transparent;
      color: var(--text);
      font-weight: 600;
    
      /* dark fill + animated rainbow border */
      background:
        linear-gradient(rgba(15,22,38,0.70), rgba(15,22,38,0.70)) padding-box,
        linear-gradient(
          90deg,
          #ff004c,
          #ff9a00,
          #ffee00,
          #00d084,
          #00aaff,
          #8a2be2,
          #ff00c8,
          #ff004c
        ) border-box;
    
      background-size: 100% 100%, 400% 100%;
      background-position: 0 0, 0% 50%;
      animation: rainbowShift 3.5s linear infinite;
    
      box-shadow: 0 0 18px rgba(255,255,255,0.06);
    }
    
    .pill--rainbow:hover{
      text-decoration: none;
      box-shadow:
        0 0 22px rgba(255,255,255,0.10),
        0 0 34px rgba(122,162,255,0.12);
    }
    
    @keyframes rainbowShift{
      to { background-position: 0 0, 400% 50%; }
    }
    
    /* Accessibility, no motion if user prefers reduced motion */
    @media (prefers-reduced-motion: reduce){
      .pill--rainbow{ animation: none; }
    }
    .hero{
      margin-top: 26px;
      padding: 34px 26px;
      border: 1px solid var(--line);
      background: linear-gradient(180deg, rgba(17,26,43,0.78), rgba(15,22,38,0.65));
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      overflow: hidden;
      position: relative;
    }
    .hero:before{
      content:"";
      position: absolute;
      inset: -40px -40px auto auto;
      width: 240px;
      height: 240px;
      background: radial-gradient(circle at 30% 30%, rgba(122,162,255,0.35), transparent 60%);
      transform: rotate(12deg);
      pointer-events: none;
    }
    .tag{
      display: inline-flex;
      gap: 8px;
      align-items: center;
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid var(--line);
      background: rgba(15,22,38,0.55);
      color: var(--muted);
      font-size: 13px;
      margin-bottom: 12px;
    }
    h1{
      margin: 0 0 10px;
      font-size: clamp(26px, 3.2vw, 44px);
      line-height: 1.12;
      letter-spacing: -0.6px;
    }
    .sub{
      margin: 0;
      color: var(--muted);
      max-width: 86ch;
      font-size: 15px;
    }
    .kpi{
      margin-top: 18px;
      display: grid;
      gap: 12px;
      grid-template-columns: repeat(3, minmax(0, 1fr));
    }
    .kpi .card{
      border: 1px solid var(--line);
      background: rgba(15,22,38,0.55);
      border-radius: 14px;
      padding: 14px 14px;
    }
    .kpi .card b{ display:block; font-size: 13px; margin-bottom: 6px; }
    .kpi .card span{ color: var(--muted); font-size: 13px; }

    section{
      margin-top: 22px;
      padding: 22px 18px;
      border: 1px solid var(--line);
      background: rgba(17,26,43,0.50);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
    }
    section h2{
      margin: 0 0 10px;
      font-size: 20px;
      letter-spacing: -0.2px;
    }
    .grid{
      display: grid;
      gap: 14px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
      align-items: start;
    }
    .box{
      padding: 14px 14px;
      border-radius: 14px;
      border: 1px solid var(--line);
      background: rgba(15,22,38,0.55);
    }
    .box h3{
      margin: 0 0 6px;
      font-size: 15px;
    }
    .box p, .box li{ color: var(--muted); }
    ul{ margin: 10px 0 0; padding-left: 18px; }

    code, pre{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 12.5px;
    }
    pre{
      margin: 12px 0 0;
      padding: 12px;
      border-radius: 14px;
      border: 1px solid var(--line);
      background: rgba(7,10,16,0.65);
      overflow: auto;
      color: #d9e6ff;
    }

    .media{
      margin-top: 12px;
      border: 1px solid var(--line);
      border-radius: 14px;
      overflow: hidden;
      background: rgba(7,10,16,0.45);
    }
    .media img{
      width: 100%;
      height: auto;
      display: block;
    }
    .caption{
      padding: 10px 12px;
      border-top: 1px solid var(--line);
      color: var(--muted);
      font-size: 13px;
    }
    .gallery{
      margin-top: 12px;
      display: grid;
      gap: 12px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
    }
    .gallery .media{ margin-top: 0; }

    .videos{
      display: grid;
      gap: 14px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
      margin-top: 12px;
    }
    .vcard{
      border: 1px solid var(--line);
      border-radius: 16px;
      background: rgba(15,22,38,0.55);
      overflow: hidden;
    }
    .vhead{
      padding: 12px 12px 10px;
      border-bottom: 1px solid var(--line);
    }
    .vhead b{ display:block; font-size: 14px; }
    .vhead span{ display:block; margin-top: 4px; color: var(--muted); font-size: 13px; }
    video{
      width: 100%;
      height: auto;
      display: block;
      background: #000;
    }

    footer{
      margin-top: 22px;
      color: var(--muted);
      font-size: 13px;
      padding: 16px 4px 0;
      opacity: 0.95;
    }

    @media (max-width: 900px){
      .kpi{ grid-template-columns: 1fr; }
      .grid{ grid-template-columns: 1fr; }
      .videos{ grid-template-columns: 1fr; }
      .gallery{ grid-template-columns: 1fr; }
      .nav{ border-radius: 18px; }
    }
  </style>
</head>

<body>
  <div class="wrap">
    <div class="nav">

      <div class="navlinks" aria-label="Page sections">
        <a class="pill" href="#intro">Introduction</a>
        <a class="pill" href="#remote">Remote control</a>
        <a class="pill" href="#lfd">LfD</a>
        <a class="pill pill--rainbow" href="#videos">Videos</a>
        <a class="pill" href="#conclusion">Conclusion</a>
      </div>
    </div>

    <header class="hero" id="top">

      <h1>Haptic Teleoperation and Learning from Demonstration with the Franka Robotic Arm</h1>

      <p class="sub">
        We teleoperated a Franka Panda robot using a Falcon haptic device through ROS, then explored Learning from Demonstration for trajectory learning.
        The learning part starts with Gaussian Mixture Model (GMM) plus Gaussian Mixture Regression (GMR), then moves to Task-Parameterized GMM to improve generalization across reference frames.
      </p>

      <div class="kpi" role="list">
        <div class="card" role="listitem">
          <b>Remote control</b>
          <span>Two PCs, ROS networking, Cartesian impedance control for position and orientation, gripper actions.</span>
        </div>
        <div class="card" role="listitem">
          <b>Force feedback</b>
          <span>No force sensor, estimate external wrench from robot state and filter noise.</span>
        </div>
        <div class="card" role="listitem">
          <b>Learning from Demonstration</b>
          <span>Learn P(x, v) with GMM, reproduce with GMR, then generalize with TP-GMM.</span>
        </div>
      </div>
    </header>

    <section id="intro">
      <h2>Introduction</h2>
      <div class="grid">
        <div class="box">
          <h3>Remote Control</h3>
          <ul>
            <li><b>Idea:</b> control a robot in real time using a haptic device.</li>
            <li><b>Applications:</b> remote surgery, hazardous environments, search and rescue.</li>
            <li><b>Why:</b> when precision or safety is critical, teleoperation can be more reliable than full autonomy.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Learning from Demonstration</h3>
          <ul>
            <li><b>Idea:</b> robots learn trajectories from human demonstrations.</li>
            <li><b>Applications:</b> assembly, complex manipulation, dynamic environments.</li>
            <li><b>Why:</b> generalize from demonstrations to new tasks, which helps adaptability.</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="remote">
      <h2>Remote control</h2>

      <div class="grid">
        <div class="box">
          <h3>System connection overview</h3>
          <ul>
            <li>Two PCs connected via ROS.</li>
            <li>PC2 connects to the robot over TCP/IP using ROS.</li>
          </ul>
          <pre><code>PC1 (Falcon device) → ROS topics → PC2 (control node) → Franka Panda</code></pre>

          <div class="media">
            <img src="./assets/images/system_connection_overview.png" alt="System connection overview diagram (PC1, PC2, ROS, Franka Panda)." loading="lazy" decoding="async" />
            <div class="caption">System connection overview.</div>
          </div>
        </div>

        <div class="box">
          <h3>Position control</h3>
          <p>
            We used Cartesian impedance control.
            The haptic device provides a desired Cartesian velocity, and we integrate it to get a desired position.
          </p>
          <ul>
            <li>Example command topic: <code>LFcommand</code></li>
            <li>Cartesian control force (typical form): <code>F = K(x_d - x) - D x_dot</code></li>
            <li>Map to joint torques (typical form): <code>tau = J^T F + C</code></li>
          </ul>

          <div class="media">
            <img src="./assets/images/position_control.png" alt="Position control details with Cartesian impedance control and LFcommand." loading="lazy" decoding="async" />
            <div class="caption">Position control details.</div>
          </div>
        </div>

        <div class="box">
          <h3>Orientation control</h3>
          <p>
            Orientation also uses impedance control, but the error comes from quaternion-based orientation difference.
            We compute an angular velocity command from that error.
          </p>
          <ul>
            <li>Example command topic: <code>OFcommand</code></li>
            <li>We compute orientation error from desired and current quaternion.</li>
          </ul>

          <div class="media">
            <img src="./assets/images/orientation_control.png" alt="Orientation control details with quaternion error and OFcommand." loading="lazy" decoding="async" />
            <div class="caption">Orientation control details.</div>
          </div>
        </div>

        <div class="box">
          <h3>Workspace adjustment</h3>
          <p>
            The Falcon workspace is small and the robot workspace is large, so we used a clutch style strategy.
            You hold a button to enable motion, and let go to keep the robot still.
          </p>
          <ul>
            <li><b>Button 0 (position):</b> long press moves, short press toggles fast or slow mode, no press holds still.</li>
            <li><b>Button 1 (orientation):</b> long press moves, no press holds still.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Gripper control</h3>
          <p>
            We used the <code>franka_gripper</code> package with <code>MoveAction</code> and <code>GraspAction</code>.
          </p>
          <ul>
            <li><b>Button 2:</b> close by 5 mm</li>
            <li><b>Button 3:</b> open by 5 mm</li>
            <li><b>Button 2 + 3:</b> grasp action</li>
          </ul>
        </div>

        <div class="box">
          <h3>Force feedback</h3>
          <p>
            We did not use a force sensor.
            Instead we used <code>robot_state.O_F_ext_hat_K</code>, which estimates external force at the end effector.
            It is noisy, so we applied a threshold filter before sending it back to the haptic device.
          </p>
          <ul>
            <li>Example feedback topic: <code>FLfeedback</code></li>
          </ul>

          <div class="media">
            <img src="./assets/images/force_feedback.png" alt="Force feedback slide showing O_F_ext_hat_K and threshold filter." loading="lazy" decoding="async" />
            <div class="caption">Force feedback summary.</div>
          </div>
        </div>

        <div class="box">
          <h3>Remote control result</h3>
          <p>
            Final result: being able to grasp an object at the desired position and orientation.
            The main demo is included as Video 1 below.
          </p>
        </div>
      </div>
    </section>

    <section id="lfd">
      <h2>Learning from Demonstration</h2>

      <div class="grid">
        <div class="box">
          <h3>Why do robots need to learn?</h3>
          <ul>
            <li>Programming every single action is costly and time consuming.</li>
            <li>There is a huge number of tasks.</li>
            <li>Environments change, sometimes dynamically.</li>
          </ul>
        </div>

        <div class="box">
          <h3>What to learn, and how?</h3>
          <ul>
            <li><b>What:</b> robot trajectories, features, state actions.</li>
            <li><b>How:</b> supervised learning, Learning from Demonstration, reinforcement learning, unsupervised learning.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Robot trajectories, collecting demonstrations</h3>
          <ul>
            <li>Put the robot in the initial position.</li>
            <li>Perform teleoperation.</li>
            <li>Save position and velocity along x, y, z.</li>
          </ul>
          <pre><code>Each demo: (x, v) pairs over time</code></pre>
        </div>

        <div class="box">
          <h3>GMM: learn the joint distribution P(x, v)</h3>
          <ul>
            <li>Model the underlying joint probability <code>P(x, v)</code>.</li>
            <li>Learn GMM parameters using Expectation Maximization (E-step, M-step).</li>
            <li>Use BIC to choose the number of mixture states.</li>
          </ul>

          <div class="gallery">
            <div class="media">
              <img src="./assets/images/lfd_pairing_position_velocity.png" alt="Demonstrations paired as position and velocity, scatter plot illustration." loading="lazy" decoding="async" />
              <div class="caption">Paired (x, v) view .</div>
            </div>
            <div class="media">
              <img src="./assets/images/lfd_gmm_learning.png" alt="GMM learning with EM and plotted demonstrations." loading="lazy" decoding="async" />
              <div class="caption">Learning GMM with EM.</div>
            </div>
          </div>
        </div>

        <div class="box">
          <h3>GMR: reproduce a trajectory</h3>
          <p>
            Having <code>P(x, v)</code> is not enough to directly output a velocity.
            With GMR we condition on the current position to predict the desired velocity.
          </p>
          <ul>
            <li>Split into input and output dimensions.</li>
            <li>Compute responsibilities at the current x.</li>
            <li>Compute <code>v | x</code> for control.</li>
          </ul>
          <p class="sub">The GMM plus GMR demo is included as Video 2.</p>
        </div>

        <div class="box">
          <h3>Why TP-GMM?</h3>
          <ul>
            <li>GMM plus GMR does not generalize well to different reference frames.</li>
            <li>Task parameters describe situations in the environment.</li>
            <li>Goal: better learning speed and better extrapolation.</li>
          </ul>
        </div>

        <div class="box">
          <h3>TP-GMM: training and reproduction</h3>
          <ul>
            <li>Use EM to fit a task-parameterized model.</li>
            <li>During reproduction, merge Gaussians from the same task parameter.</li>
            <li>Transform to the new situation, then apply GMR to get velocity.</li>
          </ul>
          <p class="sub">The TP-GMM demo is included as Video 3.</p>
        </div>

        <div class="box">
          <h3>Experiment snapshot</h3>
          <ul>
            <li>Collected 8 trajectories with different end frames, then generated 1.</li>
          </ul>

          <div class="media">
            <img src="./assets/images/lfd_tp_gmm_experiment.png" alt="TP-GMM experiment summary plot." loading="lazy" decoding="async" />
            <div class="caption">TP-GMM experiment summary.</div>
          </div>
        </div>
      </div>
    </section>

    <section id="videos">
      <h2>Videos</h2>

      <div class="videos">
        <div class="vcard">
          <div class="vhead">
            <b>Video 1: Remote control result</b>
            <span>Grasp an object at the desired position and orientation (final teleop result).</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video1.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Video 2: GMM + GMR reproduction</b>
            <span>Trajectory reproduction from demonstrations using GMM learning and GMR conditioning.</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video2.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Video 3: TP-GMM reproduction</b>
            <span>Generalization to new task frames with task-parameterized GMM.</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video3.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Video 4: Remote Control Results</b>
            <span>Grasp an object at the desired position and orientation (final teleop result).</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video4.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>
    </section>

    <section id="conclusion">
      <h2>Conclusion</h2>
      <div class="grid">
        <div class="box">
          <h3>Achievements</h3>
          <ul>
            <li>Remote control of the Franka Panda with a Falcon haptic device.</li>
            <li>Workspace adjustment without interruption.</li>
            <li>Position, orientation, and gripper control, plus basic force feedback.</li>
            <li>Learning from Demonstration for trajectory generalization.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Limitations</h3>
          <ul>
            <li>Gripper force must be predefined for objects with different weights.</li>
            <li>No vision sensor, operator still needs direct view of the robot.</li>
            <li>LfD: no dynamic environment handling, manual task frames, sensitive parameters.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Future work</h3>
          <ul>
            <li>Upgrade to a more advanced haptic device with rotation.</li>
            <li>Integrate vision sensors for true remote operation.</li>
            <li>Adaptive gripper control for different objects.</li>
            <li>Handle dynamic environments.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Contact</h3>
          <p class="sub">
            Nil Biescas, Yisheng Sun, Qingping Hu
            <br />
            Update this block with your preferred contact links before publishing.
          </p>
        </div>
      </div>
    </section>

    <footer>
      Thank you for your attention!
    </footer>
  </div>
</body>
</html>
