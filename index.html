<!doctype html>
<html:contentReference[oaicite:2]{index=2}<meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Creation of a haptic teleorobotics system with the Franka robotic arm and exploration of learning from demonstration techniques</title>
  <meta name="description" content="Final presentation: teleoperation of a Franka Panda with a Falcon haptic device, plus Learning from Demonstration using GMM/GMR and TP-GMM." />

  <style>
    :root{
      --bg: #0b0f17;
      --panel: #111a2b;
      --panel-2: #0f1626;
      --text: #e8eefc;
      --muted: #b7c3df;
      --line: rgba(232, 238, 252, 0.14);
      --accent: #7aa2ff;
      --accent-2: #8df0d6;
      --shadow: 0 10px 30px rgba(0,0,0,0.35);
      --radius: 18px;
      --maxw: 1100px;
    }
    * { box-sizing: border-box; }
    html { scroll-behavior: smooth; }
    body{
      margin: 0;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      background:
        radial-gradient(1200px 700px at 15% 10%, rgba(122,162,255,0.25), transparent 60%),
        radial-gradient(900px 600px at 80% 20%, rgba(141,240,214,0.12), transparent 55%),
        var(--bg);
      color: var(--text);
      line-height: 1.55;
    }
    a{ color: var(--text); text-decoration: none; }
    a:hover{ text-decoration: underline; }
    .wrap{ max-width: var(--maxw); margin: 0 auto; padding: 28px 20px 64px; }

    /* Nav */
    .nav{
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 18px;
      padding: 14px 16px;
      border: 1px solid var(--line);
      background: rgba(17,26,43,0.65);
      backdrop-filter: blur(10px);
      border-radius: 999px;
      box-shadow: var(--shadow);
      position: sticky;
      top: 14px;
      z-index: 10;
    }
    .brand{
      display: flex;
      align-items: center;
      gap: 10px;
      white-space: nowrap;
    }
    .dot{
      width: 10px;
      height: 10px;
      border-radius: 999px;
      background: linear-gradient(135deg, var(--accent), var(--accent-2));
      box-shadow: 0 0 0 5px rgba(122,162,255,0.12);
    }
    .brand strong{ font-size: 14px; letter-spacing: 0.4px; }
    .navlinks{
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      justify-content: flex-end;
    }
    .pill{
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border: 1px solid var(--line);
      border-radius: 999px;
      background: rgba(15,22,38,0.5);
      font-size: 13px;
      color: var(--muted);
    }
    .pill:hover{ color: var(--text); border-color: rgba(232,238,252,0.25); }

    /* Hero */
    .hero{
      margin-top: 26px;
      padding: 34px 26px;
      border: 1px solid var(--line);
      background: linear-gradient(180deg, rgba(17,26,43,0.78), rgba(15,22,38,0.65));
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      overflow: hidden;
      position: relative;
    }
    .hero:before{
      content:"";
      position: absolute;
      inset: -40px -40px auto auto;
      width: 240px;
      height: 240px;
      background: radial-gradient(circle at 30% 30%, rgba(122,162,255,0.35), transparent 60%);
      transform: rotate(12deg);
      pointer-events: none;
    }
    .tag{
      display: inline-flex;
      gap: 8px;
      align-items: center;
      padding: 6px 10px;
      border-radius: 999px;
      border: 1px solid var(--line);
      background: rgba(15,22,38,0.55);
      color: var(--muted);
      font-size: 13px;
      margin-bottom: 12px;
    }
    h1{
      margin: 0 0 10px;
      font-size: clamp(26px, 3.2vw, 44px);
      line-height: 1.12;
      letter-spacing: -0.6px;
    }
    .sub{
      margin: 0;
      color: var(--muted);
      max-width: 86ch;
      font-size: 15px;
    }
    .kpi{
      margin-top: 18px;
      display: grid;
      gap: 12px;
      grid-template-columns: repeat(3, minmax(0, 1fr));
    }
    .kpi .card{
      border: 1px solid var(--line);
      background: rgba(15,22,38,0.55);
      border-radius: 14px;
      padding: 14px 14px;
    }
    .kpi .card b{ display:block; font-size: 13px; margin-bottom: 6px; }
    .kpi .card span{ color: var(--muted); font-size: 13px; }

    /* Sections */
    section{
      margin-top: 22px;
      padding: 22px 18px;
      border: 1px solid var(--line);
      background: rgba(17,26,43,0.50);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
    }
    section h2{
      margin: 0 0 10px;
      font-size: 20px;
      letter-spacing: -0.2px;
    }
    .grid{
      display: grid;
      gap: 14px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
      align-items: start;
    }
    .box{
      padding: 14px 14px;
      border-radius: 14px;
      border: 1px solid var(--line);
      background: rgba(15,22,38,0.55);
    }
    .box h3{
      margin: 0 0 6px;
      font-size: 15px;
    }
    .box p, .box li{ color: var(--muted); }
    ul{ margin: 10px 0 0; padding-left: 18px; }

    code, pre{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 12.5px;
    }
    pre{
      margin: 12px 0 0;
      padding: 12px;
      border-radius: 14px;
      border: 1px solid var(--line);
      background: rgba(7,10,16,0.65);
      overflow: auto;
      color: #d9e6ff;
    }

    /* Media (images) */
    .media{
      margin-top: 12px;
      border: 1px solid var(--line);
      border-radius: 14px;
      overflow: hidden;
      background: rgba(7,10,16,0.45);
    }
    .media img{
      width: 100%;
      height: auto;
      display: block;
    }
    .caption{
      padding: 10px 12px;
      border-top: 1px solid var(--line);
      color: var(--muted);
      font-size: 13px;
    }
    .gallery{
      margin-top: 12px;
      display: grid;
      gap: 12px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
    }
    .gallery .media{ margin-top: 0; }

    /* Videos */
    .videos{
      display: grid;
      gap: 14px;
      grid-template-columns: repeat(2, minmax(0, 1fr));
      margin-top: 12px;
    }
    .vcard{
      border: 1px solid var(--line);
      border-radius: 16px;
      background: rgba(15,22,38,0.55);
      overflow: hidden;
    }
    .vhead{
      padding: 12px 12px 10px;
      border-bottom: 1px solid var(--line);
    }
    .vhead b{ display:block; font-size: 14px; }
    .vhead span{ display:block; margin-top: 4px; color: var(--muted); font-size: 13px; }
    video{
      width: 100%;
      height: auto;
      display: block;
      background: #000;
    }

    /* Footer */
    footer{
      margin-top: 22px;
      color: var(--muted);
      font-size: 13px;
      padding: 16px 4px 0;
      opacity: 0.95;
    }

    @media (max-width: 900px){
      .kpi{ grid-template-columns: 1fr; }
      .grid{ grid-template-columns: 1fr; }
      .videos{ grid-template-columns: 1fr; }
      .gallery{ grid-template-columns: 1fr; }
      .nav{ border-radius: 18px; }
    }
  </style>
</head>

<body>
  <div class="wrap">
    <div class="nav">
      <div class="brand">
        <span class="dot"></span>
        <strong>RMIL Project, Final Presentation</strong>
      </div>

      <div class="navlinks" aria-label="Page sections">
        <a class="pill" href="#outline">Outline</a>
        <a class="pill" href="#intro">Introduction</a>
        <a class="pill" href="#remote">Remote control</a>
        <a class="pill" href="#lfd">LfD</a>
        <a class="pill" href="#videos">Videos</a>
        <a class="pill" href="#conclusion">Conclusion</a>
      </div>
    </div>

    <header class="hero" id="top">
      <div class="tag">RMIL Project Final Presentation, 18.08</div>

      <h1>Creation of a haptic teleorobotics system with the Franka robotic arm and exploration of learning from demonstration techniques</h1>

      <p class="sub">
        This page summarizes the final presentation.
        We teleoperated a Franka Panda robot using a Falcon haptic device through ROS, then explored Learning from Demonstration for trajectory learning.
        The learning part starts with GMM plus GMR, then moves to Task-Parameterized GMM to improve generalization across reference frames.
      </p>

      <div class="kpi" role="list">
        <div class="card" role="listitem">
          <b>Remote control</b>
          <span>Two PCs, ROS networking, Cartesian impedance control for position and orientation, gripper actions.</span>
        </div>
        <div class="card" role="listitem">
          <b>Force feedback</b>
          <span>No force sensor, estimate external wrench from robot state and filter noise.</span>
        </div>
        <div class="card" role="listitem">
          <b>Learning from Demonstration</b>
          <span>Learn P(x, v) with GMM, reproduce with GMR, then generalize with TP-GMM.</span>
        </div>
      </div>
    </header>

    <section id="outline">
      <h2>Outline</h2>
      <div class="grid">
        <div class="box">
          <h3>Remote Control</h3>
          <ul>
            <li>System connection overview</li>
            <li>Position, orientation, and gripper control</li>
            <li>Force feedback</li>
            <li>Results</li>
          </ul>
        </div>

        <div class="box">
          <h3>Learning from Demonstration</h3>
          <ul>
            <li>Gaussian Mixture Model and Gaussian Mixture Regression</li>
            <li>Task-Parameterized Gaussian Mixture Model</li>
            <li>Conclusion</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="intro">
      <h2>Introduction</h2>
      <div class="grid">
        <div class="box">
          <h3>Remote Control</h3>
          <ul>
            <li><b>Idea:</b> control a robot in real time using a haptic device.</li>
            <li><b>Applications:</b> remote surgery, hazardous environments, search and rescue.</li>
            <li><b>Why:</b> when precision or safety is critical, teleoperation can be more reliable than full autonomy.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Learning from Demonstration</h3>
          <ul>
            <li><b>Idea:</b> robots learn trajectories from human demonstrations.</li>
            <li><b>Applications:</b> assembly, complex manipulation, dynamic environments.</li>
            <li><b>Why:</b> generalize from demonstrations to new tasks, which helps adaptability.</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="remote">
      <h2>Remote control</h2>

      <div class="grid">
        <div class="box">
          <h3>System connection overview</h3>
          <ul>
            <li>Two PCs connected via ROS.</li>
            <li>PC2 connects to the robot over TCP/IP using ROS.</li>
          </ul>
          <pre><code>PC1 (Falcon device) → ROS topics → PC2 (control node) → Franka Panda</code></pre>

          <div class="media">
            <img src="./assets/images/system_connection_overview.png" alt="System connection overview diagram (PC1, PC2, ROS, Franka Panda)." loading="lazy" decoding="async" />
            <div class="caption">System connection overview (slide 28).</div>
          </div>
        </div>

        <div class="box">
          <h3>Position control</h3>
          <p>
            We used Cartesian impedance control.
            The haptic device provides a desired Cartesian velocity, and we integrate it to get a desired position.
          </p>
          <ul>
            <li>Example command topic: <code>LFcommand</code></li>
            <li>Cartesian control force (typical form): <code>F = K(x_d - x) - D x_dot</code></li>
            <li>Map to joint torques (typical form): <code>tau = J^T F + C</code></li>
          </ul>

          <div class="media">
            <img src="./assets/images/position_control.png" alt="Position control slide with Cartesian impedance control and LFcommand." loading="lazy" decoding="async" />
            <div class="caption">Position control details (slide 29).</div>
          </div>
        </div>

        <div class="box">
          <h3>Orientation control</h3>
          <p>
            Orientation also uses impedance control, but the error comes from quaternion-based orientation difference.
            We compute an angular velocity command from that error.
          </p>
          <ul>
            <li>Example command topic: <code>OFcommand</code></li>
            <li>We compute orientation error from desired and current quaternion.</li>
          </ul>

          <div class="media">
            <img src="./assets/images/orientation_control.png" alt="Orientation control slide with quaternion error and OFcommand." loading="lazy" decoding="async" />
            <div class="caption">Orientation control details (slide 30).</div>
          </div>
        </div>

        <div class="box">
          <h3>Workspace adjustment</h3>
          <p>
            The Falcon workspace is small and the robot workspace is large, so we used a clutch style strategy.
            You hold a button to enable motion, and let go to keep the robot still.
          </p>
          <ul>
            <li><b>Button 0 (position):</b> long press moves, short press toggles fast or slow mode, no press holds still.</li>
            <li><b>Button 1 (orientation):</b> long press moves, no press holds still.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Gripper control</h3>
          <p>
            We used the <code>franka_gripper</code> package with <code>MoveAction</code> and <code>GraspAction</code>.
          </p>
          <ul>
            <li><b>Button 2:</b> close by 5 mm</li>
            <li><b>Button 3:</b> open by 5 mm</li>
            <li><b>Button 2 + 3:</b> grasp action</li>
          </ul>
        </div>

        <div class="box">
          <h3>Force feedback</h3>
          <p>
            We did not use a force sensor.
            Instead we used <code>robot_state.O_F_ext_hat_K</code>, which estimates external force at the end effector.
            It is noisy, so we applied a threshold filter before sending it back to the haptic device.
          </p>
          <ul>
            <li>Example feedback topic: <code>FLfeedback</code></li>
          </ul>

          <div class="media">
            <img src="./assets/images/force_feedback.png" alt="Force feedback slide showing O_F_ext_hat_K and threshold filter." loading="lazy" decoding="async" />
            <div class="caption">Force feedback summary (slide 33).</div>
          </div>
        </div>

        <div class="box">
          <h3>Remote control result</h3>
          <p>
            Final result: being able to grasp an object at the desired position and orientation.
            The main demo is included as Video 1 below.
          </p>

          <div class="media">
            <img src="./assets/images/remote_control_results.png" alt="Remote control results slide showing grasping at target pose." loading="lazy" decoding="async" />
            <div class="caption">Remote control results (slide 34).</div>
          </div>
        </div>
      </div>
    </section>

    <section id="lfd">
      <h2>Learning from Demonstration</h2>

      <div class="grid">
        <div class="box">
          <h3>Why do robots need to learn?</h3>
          <ul>
            <li>Programming every single action is costly and time consuming.</li>
            <li>There is a huge number of tasks.</li>
            <li>Environments change, sometimes dynamically.</li>
          </ul>

          <div class="media">
            <img src="./assets/images/lfd_why_learn.png" alt="Slide explaining why robots need to learn, with example illustration." loading="lazy" decoding="async" />
            <div class="caption">Motivation (slide 35).</div>
          </div>
        </div>

        <div class="box">
          <h3>What to learn, and how?</h3>
          <ul>
            <li><b>What:</b> robot trajectories, features, state actions.</li>
            <li><b>How:</b> supervised learning, Learning from Demonstration, reinforcement learning, unsupervised learning.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Robot trajectories, collecting demonstrations</h3>
          <ul>
            <li>Put the robot in the initial position.</li>
            <li>Perform teleoperation.</li>
            <li>Save position and velocity along x, y, z.</li>
          </ul>
          <pre><code>Each demo: (x, v) pairs over time</code></pre>

          <div class="media">
            <img src="./assets/images/lfd_robot_trajectories_teleoperation.png" alt="Teleoperation diagram for collecting robot demonstrations." loading="lazy" decoding="async" />
            <div class="caption">Collecting demonstrations (slide 37).</div>
          </div>
        </div>

        <div class="box">
          <h3>GMM: learn the joint distribution P(x, v)</h3>
          <ul>
            <li>Model the underlying joint probability <code>P(x, v)</code>.</li>
            <li>Learn GMM parameters using Expectation Maximization (E-step, M-step).</li>
            <li>Use BIC to choose the number of mixture states.</li>
          </ul>

          <div class="gallery">
            <div class="media">
              <img src="./assets/images/lfd_pairing_position_velocity.png" alt="Demonstrations paired as position and velocity, scatter plot illustration." loading="lazy" decoding="async" />
              <div class="caption">Paired (x, v) view (slide 38).</div>
            </div>
            <div class="media">
              <img src="./assets/images/lfd_gmm_learning.png" alt="GMM learning slide with EM and plotted demonstrations." loading="lazy" decoding="async" />
              <div class="caption">Learning GMM with EM (slide 39).</div>
            </div>
          </div>
        </div>

        <div class="box">
          <h3>GMR: reproduce a trajectory</h3>
          <p>
            Having <code>P(x, v)</code> is not enough to directly output a velocity.
            With GMR we condition on the current position to predict the desired velocity.
          </p>
          <ul>
            <li>Split into input and output dimensions.</li>
            <li>Compute responsibilities at the current x.</li>
            <li>Compute <code>v | x</code> for control.</li>
          </ul>
          <p class="sub">The GMM plus GMR demo is included as Video 2.</p>

          <div class="media">
            <img src="./assets/images/lfd_gmr_reproduction.png" alt="GMR reproduction slide showing conditioning steps and example plots." loading="lazy" decoding="async" />
            <div class="caption">GMR for reproduction (slide 40).</div>
          </div>

          <div class="media">
            <img src="./assets/images/lfd_gmm_gmr_photo.png" alt="Photo slide for GMM plus GMR experiment with the Franka robot." loading="lazy" decoding="async" />
            <div class="caption">GMM + GMR experiment snapshot (slide 41).</div>
          </div>
        </div>

        <div class="box">
          <h3>Why TP-GMM?</h3>
          <ul>
            <li>GMM plus GMR does not generalize well to different reference frames.</li>
            <li>Task parameters describe situations in the environment.</li>
            <li>Goal: better learning speed and better extrapolation.</li>
          </ul>
        </div>

        <div class="box">
          <h3>TP-GMM: training and reproduction</h3>
          <ul>
            <li>Use EM to fit a task-parameterized model.</li>
            <li>During reproduction, merge Gaussians from the same task parameter.</li>
            <li>Transform to the new situation, then apply GMR to get velocity.</li>
          </ul>
          <p class="sub">The TP-GMM demo is included as Video 3.</p>

          <div class="media">
            <img src="./assets/images/lfd_tp_gmm_overview.png" alt="TP-GMM overview slide with task parameters and reproduction pipeline." loading="lazy" decoding="async" />
            <div class="caption">TP-GMM overview (slide 43).</div>
          </div>
        </div>

        <div class="box">
          <h3>Experiment snapshot</h3>
          <ul>
            <li>Collected 8 trajectories with different end frames, then generated 1.</li>
          </ul>

          <div class="media">
            <img src="./assets/images/lfd_tp_gmm_experiment.png" alt="TP-GMM experiment slide with 3D plot of demonstrations and reproduction." loading="lazy" decoding="async" />
            <div class="caption">TP-GMM experiment summary (slide 44).</div>
          </div>
        </div>
      </div>
    </section>

    <section id="videos">
      <h2>Videos</h2>
      <p class="sub">
        Put your clips into <code>assets/videos/</code>.
        These players point to three files. If a file is missing, you will see an empty player until you upload it.
      </p>

      <div class="videos">
        <div class="vcard">
          <div class="vhead">
            <b>Video 1: Remote control result</b>
            <span>Grasp an object at the desired position and orientation (final teleop result).</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video1.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Video 2: GMM + GMR reproduction</b>
            <span>Trajectory reproduction from demonstrations using GMM learning and GMR conditioning.</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video2.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Video 3: TP-GMM reproduction</b>
            <span>Generalization to new task frames with task-parameterized GMM.</span>
          </div>
          <video controls preload="metadata">
            <source src="./assets/videos/video3.mp4" type="video/mp4" />
            Your browser does not support the video tag.
          </video>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Optional extras</b>
            <span>If you later add more clips, duplicate a card and point to a new filename.</span>
          </div>
          <div style="padding:12px;color:var(--muted);">
            Suggested filenames:
            <div style="margin-top:8px;">
              <code>./assets/videos/video4.mp4</code> (workspace adjustment or orientation control)
              <br />
              <code>./assets/videos/video5.mp4</code> (second TP-GMM run, comparison, or failure cases)
            </div>
          </div>
        </div>

        <div class="vcard">
          <div class="vhead">
            <b>Tip</b>
            <span>Use MP4 (H.264). Keep files small so GitHub Pages loads fast.</span>
          </div>
          <div style="padding:12px;color:var(--muted);">
            If you prefer different filenames, rename them here and in your repo.
          </div>
        </div>
      </div>
    </section>

    <section id="conclusion">
      <h2>Conclusion</h2>
      <div class="grid">
        <div class="box">
          <h3>Achievements</h3>
          <ul>
            <li>Remote control of the Franka Panda with a Falcon haptic device.</li>
            <li>Workspace adjustment without interruption.</li>
            <li>Position, orientation, and gripper control, plus basic force feedback.</li>
            <li>Learning from Demonstration for trajectory generalization.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Limitations</h3>
          <ul>
            <li>Gripper force must be predefined for objects with different weights.</li>
            <li>No vision sensor, operator still needs direct view of the robot.</li>
            <li>LfD: no dynamic environment handling, manual task frames, sensitive parameters.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Future work</h3>
          <ul>
            <li>Upgrade to a more advanced haptic device with rotation.</li>
            <li>Integrate vision sensors for true remote operation.</li>
            <li>Adaptive gripper control for different objects.</li>
            <li>Handle dynamic environments.</li>
          </ul>
        </div>

        <div class="box">
          <h3>Contact</h3>
          <p class="sub">
            Nil Biescas, Yisheng Sun, Qingping Hu
            <br />
            Update this block with your preferred contact links before publishing.
          </p>
        </div>
      </div>
    </section>

    <footer>
      Thank you for your attention!
    </footer>
  </div>
</body>
</html>
